# Inventory AI Management API  
### Inventory Chatbot with "Present Query" Output  
Assignment â€“ DataHub (Hady Rashad)

---

## ğŸ“Œ Project Objective

Design and implement a minimal AI chat service in Python that:

- Answers inventory/business questions
- Returns the exact SQL query that would be executed ("Present Query")
- Uses SQL Server as the database
- Integrates with an AI provider (Local LLM via Ollama)

This project demonstrates:
- Natural Language â†’ SQL generation
- Present Query output
- Safe SQL execution (SELECT only)
- Real database results summarization

---

## ğŸ—ï¸ Architecture Overview

User Question  
â¬‡  
POST `/api/chat` (FastAPI)  
â¬‡  
Local LLM (Ollama + llama3) generates SQL  
â¬‡  
SQL Safety Gate (SELECT only)  
â¬‡  
SQL Server Execution  
â¬‡  
LLM summarizes result  
â¬‡  
JSON Response (Answer + SQL + Data)

---

## ğŸ› ï¸ Tech Stack

- Python 3.13
- FastAPI
- Uvicorn
- SQLAlchemy
- SQL Server (SQLEXPRESS)
- ODBC Driver 18
- Ollama (Local LLM)
- llama3 model
- requests

---

## ğŸ“‚ Project Structure


inventory_ai/
â”‚
â”œâ”€â”€ config.py
â”œâ”€â”€ database.py
â”œâ”€â”€ inventory.py
â”œâ”€â”€ llm_client.py
â”œâ”€â”€ server.py
â”œâ”€â”€ populate_db.py
â”œâ”€â”€ test_connection.py
â”œâ”€â”€ test_run.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## ğŸ—„ï¸ Database Schema (Current Implementation)

### Sites
- id (Primary Key)
- name (Unique)
- location

### Assets
- id (Primary Key)
- name
- category
- site_id (Foreign Key â†’ Sites.id)

---

## ğŸš€ API Endpoints

### CRUD Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | /sites | Create a new site |
| GET | /sites | Get all sites |
| POST | /assets | Create a new asset |
| GET | /assets | Get all assets |

---

### ğŸ¤– AI Chat Endpoint

**POST /api/chat**

#### Request Body
```json
{
  "session_id": "string",
  "message": "How many assets do I have?",
  "context": {}
}
Response Format
{
  "natural_language_answer": "You have 5 assets.",
  "sql_query": "SELECT COUNT(*) FROM Assets;",
  "data": 5,
  "latency_ms": 120,
  "provider": "ollama",
  "model": "llama3",
  "status": "ok"
}
ğŸ§  Example Queries
1ï¸âƒ£ How many assets do I have?

SQL Generated:

SELECT COUNT(*) FROM Assets;

Answer:
"You currently have 5 assets."

2ï¸âƒ£ How many assets by site?

SQL Generated:

SELECT s.name AS SiteName, COUNT(a.id) AS AssetCount
FROM Sites s
JOIN Assets a ON s.id = a.site_id
GROUP BY s.name;
ğŸ”’ Security Layer

Only SELECT queries allowed

Blocks:

INSERT

UPDATE

DELETE

DROP

ALTER

EXEC

Restricted to known tables only

Prevents destructive operations

âš™ï¸ How to Run the Project
1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
2ï¸âƒ£ Pull Local Model
ollama pull llama3
3ï¸âƒ£ Start Server
uvicorn server:app --reload
4ï¸âƒ£ Open Swagger
http://127.0.0.1:8000/docs
ğŸ§ª Test via Script
python test_run.py
ğŸ”® Future Enhancements

Add full assignment schema (Customers, Vendors, Orders, Bills, Transactions)

Add JWT Authentication

Add logging and monitoring

Improve SQL validation with parser

Add pagination for large datasets

ğŸ“ Notes

This implementation uses Local LLM (Ollama) instead of OpenAI/Azure.

Architecture allows easy switch to OpenAI/Azure via environment variables.

Demonstrates complete â€œPresent Queryâ€ pattern with real SQL execution.
